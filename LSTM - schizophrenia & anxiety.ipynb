{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d81ef43",
   "metadata": {
    "id": "4d81ef43"
   },
   "source": [
    "# MindInsight Classifier: Unveiling Mental Health Patterns in Pandemic Discourse through Data-Driven Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fff27a",
   "metadata": {
    "id": "d0fff27a"
   },
   "source": [
    "Let us first import the pertinent libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75f7a3d1",
   "metadata": {
    "id": "75f7a3d1"
   },
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5a0274",
   "metadata": {
    "id": "ec5a0274"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f385544",
   "metadata": {
    "id": "6f385544"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('mental_disorders_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d476b8d",
   "metadata": {
    "id": "1d476b8d",
    "outputId": "55a3090c-928f-4646-c170-11838f1bfee8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life is so pointless without others</td>\n",
       "      <td>Does anyone else think the most important part...</td>\n",
       "      <td>1650356960</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cold rage?</td>\n",
       "      <td>Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...</td>\n",
       "      <td>1650356660</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I donâ€™t know who I am</td>\n",
       "      <td>My [F20] bf [M20] told me today (after I said ...</td>\n",
       "      <td>1650355379</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HELP! Opinions! Advice!</td>\n",
       "      <td>Okay, Iâ€™m about to open up about many things I...</td>\n",
       "      <td>1650353430</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1650350907</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Life is so pointless without others   \n",
       "1                           Cold rage?   \n",
       "2                I donâ€™t know who I am   \n",
       "3              HELP! Opinions! Advice!   \n",
       "4                                 help   \n",
       "\n",
       "                                            selftext  created_utc  over_18  \\\n",
       "0  Does anyone else think the most important part...   1650356960    False   \n",
       "1  Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...   1650356660    False   \n",
       "2  My [F20] bf [M20] told me today (after I said ...   1650355379    False   \n",
       "3  Okay, Iâ€™m about to open up about many things I...   1650353430    False   \n",
       "4                                          [removed]   1650350907    False   \n",
       "\n",
       "  subreddit  \n",
       "0       BPD  \n",
       "1       BPD  \n",
       "2       BPD  \n",
       "3       BPD  \n",
       "4       BPD  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea1238",
   "metadata": {
    "id": "89ea1238"
   },
   "source": [
    "### Data Preprocessing and Simple EDA (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf6c318",
   "metadata": {
    "id": "fbf6c318",
    "outputId": "78c2a53d-3563-47ef-ab21-5de93144781f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(701787, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0db22d",
   "metadata": {
    "id": "af0db22d",
    "outputId": "8ac4d457-cdbd-47f7-b9cd-245a04e1cb17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             46\n",
       "selftext       33691\n",
       "created_utc        0\n",
       "over_18            0\n",
       "subreddit          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc7f05c",
   "metadata": {
    "id": "ffc7f05c"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['selftext'], how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5786258d",
   "metadata": {
    "id": "5786258d",
    "outputId": "499b4e3e-3204-4c86-9f2a-611696d7b6cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          42\n",
       "selftext        0\n",
       "created_utc     0\n",
       "over_18         0\n",
       "subreddit       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae98b60",
   "metadata": {
    "id": "2ae98b60",
    "outputId": "2a409d0f-962b-4349-f4e3-ae08afe503b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPD              233125\n",
       "Anxiety          167059\n",
       "depression       156717\n",
       "bipolar           46666\n",
       "mentalillness     44249\n",
       "schizophrenia     20280\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f63d3a2",
   "metadata": {
    "id": "8f63d3a2"
   },
   "outputs": [],
   "source": [
    "df['title'] = df['title'].fillna('')\n",
    "\n",
    "# Calculate the total number of words in 'title'\n",
    "df['title_total'] = df['title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Define a function to count total characters in a text (excluding spaces)\n",
    "def count_total_words(text):\n",
    "    char = 0\n",
    "    for word in text.split():\n",
    "        char += len(word)\n",
    "    return char\n",
    "\n",
    "# Calculate the total number of characters in 'title'\n",
    "df['title_chars'] = df['title'].apply(count_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e56c20",
   "metadata": {
    "id": "18e56c20",
    "outputId": "9e6459e4-73f8-4e02-aaa4-323842facb53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life is so pointless without others</td>\n",
       "      <td>Does anyone else think the most important part...</td>\n",
       "      <td>1650356960</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cold rage?</td>\n",
       "      <td>Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...</td>\n",
       "      <td>1650356660</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I donâ€™t know who I am</td>\n",
       "      <td>My [F20] bf [M20] told me today (after I said ...</td>\n",
       "      <td>1650355379</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HELP! Opinions! Advice!</td>\n",
       "      <td>Okay, Iâ€™m about to open up about many things I...</td>\n",
       "      <td>1650353430</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1650350907</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Life is so pointless without others   \n",
       "1                           Cold rage?   \n",
       "2                I donâ€™t know who I am   \n",
       "3              HELP! Opinions! Advice!   \n",
       "4                                 help   \n",
       "\n",
       "                                            selftext  created_utc  over_18  \\\n",
       "0  Does anyone else think the most important part...   1650356960    False   \n",
       "1  Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...   1650356660    False   \n",
       "2  My [F20] bf [M20] told me today (after I said ...   1650355379    False   \n",
       "3  Okay, Iâ€™m about to open up about many things I...   1650353430    False   \n",
       "4                                          [removed]   1650350907    False   \n",
       "\n",
       "  subreddit  title_total  title_chars  \n",
       "0       BPD            6           30  \n",
       "1       BPD            2            9  \n",
       "2       BPD            6           16  \n",
       "3       BPD            3           21  \n",
       "4       BPD            1            4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c477c22",
   "metadata": {
    "id": "9c477c22"
   },
   "outputs": [],
   "source": [
    "df['text_total'] = df['selftext'].apply(lambda x: len(x.split()))\n",
    "\n",
    "def count_total_words(text):\n",
    "    char = 0\n",
    "    for word in text.split():\n",
    "        char += len(word)\n",
    "    return char\n",
    "\n",
    "df['text_chars'] = df[\"selftext\"].apply(count_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472c5307",
   "metadata": {
    "id": "472c5307",
    "outputId": "a4ca2b65-baea-4b4e-b21f-9375f1b48245"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life is so pointless without others</td>\n",
       "      <td>Does anyone else think the most important part...</td>\n",
       "      <td>1650356960</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cold rage?</td>\n",
       "      <td>Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...</td>\n",
       "      <td>1650356660</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>517</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I donâ€™t know who I am</td>\n",
       "      <td>My [F20] bf [M20] told me today (after I said ...</td>\n",
       "      <td>1650355379</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>145</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HELP! Opinions! Advice!</td>\n",
       "      <td>Okay, Iâ€™m about to open up about many things I...</td>\n",
       "      <td>1650353430</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>821</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1650350907</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Life is so pointless without others   \n",
       "1                           Cold rage?   \n",
       "2                I donâ€™t know who I am   \n",
       "3              HELP! Opinions! Advice!   \n",
       "4                                 help   \n",
       "\n",
       "                                            selftext  created_utc  over_18  \\\n",
       "0  Does anyone else think the most important part...   1650356960    False   \n",
       "1  Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...   1650356660    False   \n",
       "2  My [F20] bf [M20] told me today (after I said ...   1650355379    False   \n",
       "3  Okay, Iâ€™m about to open up about many things I...   1650353430    False   \n",
       "4                                          [removed]   1650350907    False   \n",
       "\n",
       "  subreddit  title_total  title_chars  text_total  text_chars  \n",
       "0       BPD            6           30          74         310  \n",
       "1       BPD            2            9         517        2259  \n",
       "2       BPD            6           16         145         545  \n",
       "3       BPD            3           21         821        3282  \n",
       "4       BPD            1            4           1           9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3fbca",
   "metadata": {
    "id": "c6b3fbca"
   },
   "source": [
    "### Data Downsizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7dc34a",
   "metadata": {
    "id": "5d7dc34a",
    "outputId": "1551d8ae-dec6-4743-98d9-340e7544a8a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 668096 entries, 0 to 701786\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        668096 non-null  object\n",
      " 1   selftext     668096 non-null  object\n",
      " 2   created_utc  668096 non-null  int64 \n",
      " 3   over_18      668096 non-null  bool  \n",
      " 4   subreddit    668096 non-null  object\n",
      " 5   title_total  668096 non-null  int64 \n",
      " 6   title_chars  668096 non-null  int64 \n",
      " 7   text_total   668096 non-null  int64 \n",
      " 8   text_chars   668096 non-null  int64 \n",
      "dtypes: bool(1), int64(5), object(3)\n",
      "memory usage: 46.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c485fe6",
   "metadata": {
    "id": "0c485fe6"
   },
   "source": [
    "The number of data is 666,8096. It is very large and takes a lot of time to process. As we wish to spotlight the posts published during the duration of the COVID-19 pandemic, we will be limiting our data to only include posts from March 2020 onwards. A random sample of 10,000 posts will be taken from the dataset for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a921dba9",
   "metadata": {
    "id": "a921dba9"
   },
   "outputs": [],
   "source": [
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0d2016",
   "metadata": {
    "id": "0b0d2016",
    "outputId": "b8bbde38-1b24-44e5-feda-f80ef8225209"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life is so pointless without others</td>\n",
       "      <td>Does anyone else think the most important part...</td>\n",
       "      <td>2022-04-19 08:29:20</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cold rage?</td>\n",
       "      <td>Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect...</td>\n",
       "      <td>2022-04-19 08:24:20</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>517</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I donâ€™t know who I am</td>\n",
       "      <td>My [F20] bf [M20] told me today (after I said ...</td>\n",
       "      <td>2022-04-19 08:02:59</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>145</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HELP! Opinions! Advice!</td>\n",
       "      <td>Okay, Iâ€™m about to open up about many things I...</td>\n",
       "      <td>2022-04-19 07:30:30</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>821</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2022-04-19 06:48:27</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Life is so pointless without others   \n",
       "1                           Cold rage?   \n",
       "2                I donâ€™t know who I am   \n",
       "3              HELP! Opinions! Advice!   \n",
       "4                                 help   \n",
       "\n",
       "                                            selftext         created_utc  \\\n",
       "0  Does anyone else think the most important part... 2022-04-19 08:29:20   \n",
       "1  Hello fellow friends ðŸ˜„\\n\\nI'm on the BPD spect... 2022-04-19 08:24:20   \n",
       "2  My [F20] bf [M20] told me today (after I said ... 2022-04-19 08:02:59   \n",
       "3  Okay, Iâ€™m about to open up about many things I... 2022-04-19 07:30:30   \n",
       "4                                          [removed] 2022-04-19 06:48:27   \n",
       "\n",
       "   over_18 subreddit  title_total  title_chars  text_total  text_chars  \n",
       "0    False       BPD            6           30          74         310  \n",
       "1    False       BPD            2            9         517        2259  \n",
       "2    False       BPD            6           16         145         545  \n",
       "3    False       BPD            3           21         821        3282  \n",
       "4    False       BPD            1            4           1           9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e15043",
   "metadata": {
    "id": "f2e15043"
   },
   "outputs": [],
   "source": [
    "# Filter posts from March 2020 onwards\n",
    "filtered_df = df[df['created_utc'] >= '2020-03-01']\n",
    "\n",
    "# Take a random sample of 10,000 posts\n",
    "sampled_df = filtered_df.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816488c1",
   "metadata": {
    "id": "816488c1",
    "outputId": "081f9bfc-ceba-416c-f79f-77f73f97da82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131450</th>\n",
       "      <td>Looking for hope (feeling fed up)</td>\n",
       "      <td>My diagnosis is fairly new and I havent starte...</td>\n",
       "      <td>2020-05-30 22:47:57</td>\n",
       "      <td>False</td>\n",
       "      <td>BPD</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>344</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691395</th>\n",
       "      <td>Get motivated with determination you can do an...</td>\n",
       "      <td>Like I just managed to cut with a safety razor</td>\n",
       "      <td>2020-05-17 15:31:50</td>\n",
       "      <td>False</td>\n",
       "      <td>mentalillness</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275676</th>\n",
       "      <td>memory flashes</td>\n",
       "      <td>so, I used to have a really good memory\\n\\n&amp;am...</td>\n",
       "      <td>2022-10-13 18:02:41</td>\n",
       "      <td>False</td>\n",
       "      <td>bipolar</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392360</th>\n",
       "      <td>I'll never get to live in the fantasy land for...</td>\n",
       "      <td>I won't ever get to turn my fantasies into rea...</td>\n",
       "      <td>2022-03-01 07:58:19</td>\n",
       "      <td>False</td>\n",
       "      <td>depression</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313915</th>\n",
       "      <td>It's my 27 birthday and I don't know wtf with ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2022-02-26 21:42:56</td>\n",
       "      <td>False</td>\n",
       "      <td>depression</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "131450                  Looking for hope (feeling fed up)   \n",
       "691395  Get motivated with determination you can do an...   \n",
       "275676                                     memory flashes   \n",
       "392360  I'll never get to live in the fantasy land for...   \n",
       "313915  It's my 27 birthday and I don't know wtf with ...   \n",
       "\n",
       "                                                 selftext         created_utc  \\\n",
       "131450  My diagnosis is fairly new and I havent starte... 2020-05-30 22:47:57   \n",
       "691395     Like I just managed to cut with a safety razor 2020-05-17 15:31:50   \n",
       "275676  so, I used to have a really good memory\\n\\n&am... 2022-10-13 18:02:41   \n",
       "392360  I won't ever get to turn my fantasies into rea... 2022-03-01 07:58:19   \n",
       "313915                                          [removed] 2022-02-26 21:42:56   \n",
       "\n",
       "        over_18      subreddit  title_total  title_chars  text_total  \\\n",
       "131450    False            BPD            6           28         344   \n",
       "691395    False  mentalillness            8           45          10   \n",
       "275676    False        bipolar            2           13          91   \n",
       "392360    False     depression           10           41          72   \n",
       "313915    False     depression           13           50           1   \n",
       "\n",
       "        text_chars  \n",
       "131450        1414  \n",
       "691395          37  \n",
       "275676         424  \n",
       "392360         288  \n",
       "313915           9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fe946ad",
   "metadata": {
    "id": "9fe946ad",
    "outputId": "9bfe5136-ebab-4d31-d9f6-08e0d078c128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depression       297\n",
       "Anxiety          275\n",
       "BPD              247\n",
       "mentalillness     77\n",
       "bipolar           72\n",
       "schizophrenia     32\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cff516",
   "metadata": {
    "id": "d7cff516"
   },
   "source": [
    "### Recategorizing 'subreddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5185fb52",
   "metadata": {
    "id": "5185fb52"
   },
   "outputs": [],
   "source": [
    "# def mental_disorders(ex):\n",
    "#     if ex == 'BPD':\n",
    "#         return 'BPD'\n",
    "#     elif ex == 'bipolar':\n",
    "#         return 'bipolar'\n",
    "#     elif ex == 'Anxiety':\n",
    "#         return 'anxiety'\n",
    "#     elif ex == 'schizophrenia':\n",
    "#         return 'schizophrenia'\n",
    "#     elif ex == 'depression':\n",
    "#         return 'depression'\n",
    "#     else:\n",
    "#         return 'others'\n",
    "\n",
    "def mental_disorders(ex):\n",
    "    if ex== 'schizophrenia':\n",
    "        return 'schizophrenia'\n",
    "    elif ex == 'Anxiety':\n",
    "        return 'Anxiety'\n",
    "    else:\n",
    "        return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dda2f5aa",
   "metadata": {
    "id": "dda2f5aa"
   },
   "outputs": [],
   "source": [
    "sampled_df['subreddit'] = sampled_df['subreddit'].apply(mental_disorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac02ab71",
   "metadata": {
    "id": "ac02ab71",
    "outputId": "7db0956a-ba62-4fb6-9a16-5ef169e7687a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131450</th>\n",
       "      <td>Looking for hope (feeling fed up)</td>\n",
       "      <td>My diagnosis is fairly new and I havent starte...</td>\n",
       "      <td>2020-05-30 22:47:57</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>344</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691395</th>\n",
       "      <td>Get motivated with determination you can do an...</td>\n",
       "      <td>Like I just managed to cut with a safety razor</td>\n",
       "      <td>2020-05-17 15:31:50</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275676</th>\n",
       "      <td>memory flashes</td>\n",
       "      <td>so, I used to have a really good memory\\n\\n&amp;am...</td>\n",
       "      <td>2022-10-13 18:02:41</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392360</th>\n",
       "      <td>I'll never get to live in the fantasy land for...</td>\n",
       "      <td>I won't ever get to turn my fantasies into rea...</td>\n",
       "      <td>2022-03-01 07:58:19</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313915</th>\n",
       "      <td>It's my 27 birthday and I don't know wtf with ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2022-02-26 21:42:56</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ?</td>\n",
       "      <td>I've been medically diagnosed with a general a...</td>\n",
       "      <td>2021-08-06 01:54:21</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293850</th>\n",
       "      <td>Breakup depression and self isolated without r...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2022-08-06 09:23:21</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402501</th>\n",
       "      <td>I really canâ€™t get out of this</td>\n",
       "      <td>The last month my depression reach its lowest ...</td>\n",
       "      <td>2022-07-05 22:33:20</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>168</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦.</td>\n",
       "      <td>just had to reschedule a doctorâ€™s appointment ...</td>\n",
       "      <td>2021-08-18 22:51:22</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>192</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357103</th>\n",
       "      <td>My dog died and I have nothing left.</td>\n",
       "      <td>My marriage isn't doing great. Dog was healthy...</td>\n",
       "      <td>2022-08-25 20:40:17</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>196</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443776</th>\n",
       "      <td>Spiraling out of control</td>\n",
       "      <td>Do you ever get to where you feel fine one min...</td>\n",
       "      <td>2022-05-09 02:03:26</td>\n",
       "      <td>True</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>146</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87944</th>\n",
       "      <td>Pms exacerbating neediness for fp</td>\n",
       "      <td>I've been working hard with my therapist on co...</td>\n",
       "      <td>2021-01-18 00:09:14</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR?</td>\n",
       "      <td>Has anyone here used emdr therapy before? And ...</td>\n",
       "      <td>2022-02-27 04:59:27</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>Is anyone on amitriptyline?</td>\n",
       "      <td>Whatâ€™s your experience with amitriptyline? Iâ€™m...</td>\n",
       "      <td>2020-06-30 08:41:15</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671805</th>\n",
       "      <td>is this my rejection sensitivity or am i allow...</td>\n",
       "      <td>hi there! \\nso about two days ago i had what s...</td>\n",
       "      <td>2021-01-25 13:54:05</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>239</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412371</th>\n",
       "      <td>My friends donâ€™t care</td>\n",
       "      <td>Iâ€™ve been best friends with my group for over ...</td>\n",
       "      <td>2022-10-23 20:53:35</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>438</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym</td>\n",
       "      <td>I used to train by myself. Now I'm coming to n...</td>\n",
       "      <td>2021-07-20 11:43:14</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379648</th>\n",
       "      <td>1st time on medication</td>\n",
       "      <td>Holy crap, I have been chronically depressed f...</td>\n",
       "      <td>2022-03-15 18:59:20</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>269</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140144</th>\n",
       "      <td>A mom learning a lot about BPD and DBT.</td>\n",
       "      <td>My 17yr old daughter is now beginning her jour...</td>\n",
       "      <td>2020-07-22 04:36:36</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>93</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66199</th>\n",
       "      <td>Just received my diagnosis. Now what?</td>\n",
       "      <td>My doctor just gave me a Bpd diagnosis. He is ...</td>\n",
       "      <td>2021-01-05 18:01:15</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "131450                  Looking for hope (feeling fed up)   \n",
       "691395  Get motivated with determination you can do an...   \n",
       "275676                                     memory flashes   \n",
       "392360  I'll never get to live in the fantasy land for...   \n",
       "313915  It's my 27 birthday and I don't know wtf with ...   \n",
       "538129                       tips for managing the AAAA ?   \n",
       "293850  Breakup depression and self isolated without r...   \n",
       "402501                     I really canâ€™t get out of this   \n",
       "566855           anxiety over such insignificant thingsâ€¦.   \n",
       "357103               My dog died and I have nothing left.   \n",
       "443776                           Spiraling out of control   \n",
       "87944                   Pms exacerbating neediness for fp   \n",
       "496598                                              EMDR?   \n",
       "115086                        Is anyone on amitriptyline?   \n",
       "671805  is this my rejection sensitivity or am i allow...   \n",
       "412371                              My friends donâ€™t care   \n",
       "613187                Getting anxious about coming to gym   \n",
       "379648                             1st time on medication   \n",
       "140144            A mom learning a lot about BPD and DBT.   \n",
       "66199               Just received my diagnosis. Now what?   \n",
       "\n",
       "                                                 selftext         created_utc  \\\n",
       "131450  My diagnosis is fairly new and I havent starte... 2020-05-30 22:47:57   \n",
       "691395     Like I just managed to cut with a safety razor 2020-05-17 15:31:50   \n",
       "275676  so, I used to have a really good memory\\n\\n&am... 2022-10-13 18:02:41   \n",
       "392360  I won't ever get to turn my fantasies into rea... 2022-03-01 07:58:19   \n",
       "313915                                          [removed] 2022-02-26 21:42:56   \n",
       "538129  I've been medically diagnosed with a general a... 2021-08-06 01:54:21   \n",
       "293850                                          [removed] 2022-08-06 09:23:21   \n",
       "402501  The last month my depression reach its lowest ... 2022-07-05 22:33:20   \n",
       "566855  just had to reschedule a doctorâ€™s appointment ... 2021-08-18 22:51:22   \n",
       "357103  My marriage isn't doing great. Dog was healthy... 2022-08-25 20:40:17   \n",
       "443776  Do you ever get to where you feel fine one min... 2022-05-09 02:03:26   \n",
       "87944   I've been working hard with my therapist on co... 2021-01-18 00:09:14   \n",
       "496598  Has anyone here used emdr therapy before? And ... 2022-02-27 04:59:27   \n",
       "115086  Whatâ€™s your experience with amitriptyline? Iâ€™m... 2020-06-30 08:41:15   \n",
       "671805  hi there! \\nso about two days ago i had what s... 2021-01-25 13:54:05   \n",
       "412371  Iâ€™ve been best friends with my group for over ... 2022-10-23 20:53:35   \n",
       "613187  I used to train by myself. Now I'm coming to n... 2021-07-20 11:43:14   \n",
       "379648  Holy crap, I have been chronically depressed f... 2022-03-15 18:59:20   \n",
       "140144  My 17yr old daughter is now beginning her jour... 2020-07-22 04:36:36   \n",
       "66199   My doctor just gave me a Bpd diagnosis. He is ... 2021-01-05 18:01:15   \n",
       "\n",
       "        over_18 subreddit  title_total  title_chars  text_total  text_chars  \n",
       "131450    False    others            6           28         344        1414  \n",
       "691395    False    others            8           45          10          37  \n",
       "275676    False    others            2           13          91         424  \n",
       "392360    False    others           10           41          72         288  \n",
       "313915    False    others           13           50           1           9  \n",
       "538129    False   Anxiety            6           23         113         506  \n",
       "293850    False    others            7           49           1           9  \n",
       "402501    False    others            7           24         168         698  \n",
       "566855    False   Anxiety            5           36         192         860  \n",
       "357103    False    others            8           29         196         757  \n",
       "443776     True    others            4           21         146         650  \n",
       "87944     False    others            5           29          90         381  \n",
       "496598    False   Anxiety            1            5          14          61  \n",
       "115086    False    others            4           24          88         435  \n",
       "671805    False    others           16           63         239        1036  \n",
       "412371    False    others            4           18         438        1806  \n",
       "613187    False   Anxiety            6           30          49         221  \n",
       "379648    False    others            4           19         269        1148  \n",
       "140144    False    others            9           31          93         413  \n",
       "66199     False    others            6           32         104         420  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcfcb147",
   "metadata": {
    "id": "bcfcb147"
   },
   "outputs": [],
   "source": [
    "# We will remove the rows under selftext with have '[removed]'\n",
    "\n",
    "sampled_df = sampled_df[sampled_df['selftext'] != '[removed]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d85a060",
   "metadata": {
    "id": "3d85a060",
    "outputId": "13eb90bd-5528-4e4a-db12-1cddc3c332cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131450</th>\n",
       "      <td>Looking for hope (feeling fed up)</td>\n",
       "      <td>My diagnosis is fairly new and I havent starte...</td>\n",
       "      <td>2020-05-30 22:47:57</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>344</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691395</th>\n",
       "      <td>Get motivated with determination you can do an...</td>\n",
       "      <td>Like I just managed to cut with a safety razor</td>\n",
       "      <td>2020-05-17 15:31:50</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275676</th>\n",
       "      <td>memory flashes</td>\n",
       "      <td>so, I used to have a really good memory\\n\\n&amp;am...</td>\n",
       "      <td>2022-10-13 18:02:41</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392360</th>\n",
       "      <td>I'll never get to live in the fantasy land for...</td>\n",
       "      <td>I won't ever get to turn my fantasies into rea...</td>\n",
       "      <td>2022-03-01 07:58:19</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ?</td>\n",
       "      <td>I've been medically diagnosed with a general a...</td>\n",
       "      <td>2021-08-06 01:54:21</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402501</th>\n",
       "      <td>I really canâ€™t get out of this</td>\n",
       "      <td>The last month my depression reach its lowest ...</td>\n",
       "      <td>2022-07-05 22:33:20</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>168</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦.</td>\n",
       "      <td>just had to reschedule a doctorâ€™s appointment ...</td>\n",
       "      <td>2021-08-18 22:51:22</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>192</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357103</th>\n",
       "      <td>My dog died and I have nothing left.</td>\n",
       "      <td>My marriage isn't doing great. Dog was healthy...</td>\n",
       "      <td>2022-08-25 20:40:17</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>196</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443776</th>\n",
       "      <td>Spiraling out of control</td>\n",
       "      <td>Do you ever get to where you feel fine one min...</td>\n",
       "      <td>2022-05-09 02:03:26</td>\n",
       "      <td>True</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>146</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87944</th>\n",
       "      <td>Pms exacerbating neediness for fp</td>\n",
       "      <td>I've been working hard with my therapist on co...</td>\n",
       "      <td>2021-01-18 00:09:14</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR?</td>\n",
       "      <td>Has anyone here used emdr therapy before? And ...</td>\n",
       "      <td>2022-02-27 04:59:27</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>Is anyone on amitriptyline?</td>\n",
       "      <td>Whatâ€™s your experience with amitriptyline? Iâ€™m...</td>\n",
       "      <td>2020-06-30 08:41:15</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671805</th>\n",
       "      <td>is this my rejection sensitivity or am i allow...</td>\n",
       "      <td>hi there! \\nso about two days ago i had what s...</td>\n",
       "      <td>2021-01-25 13:54:05</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>239</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412371</th>\n",
       "      <td>My friends donâ€™t care</td>\n",
       "      <td>Iâ€™ve been best friends with my group for over ...</td>\n",
       "      <td>2022-10-23 20:53:35</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>438</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym</td>\n",
       "      <td>I used to train by myself. Now I'm coming to n...</td>\n",
       "      <td>2021-07-20 11:43:14</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379648</th>\n",
       "      <td>1st time on medication</td>\n",
       "      <td>Holy crap, I have been chronically depressed f...</td>\n",
       "      <td>2022-03-15 18:59:20</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>269</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140144</th>\n",
       "      <td>A mom learning a lot about BPD and DBT.</td>\n",
       "      <td>My 17yr old daughter is now beginning her jour...</td>\n",
       "      <td>2020-07-22 04:36:36</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>93</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66199</th>\n",
       "      <td>Just received my diagnosis. Now what?</td>\n",
       "      <td>My doctor just gave me a Bpd diagnosis. He is ...</td>\n",
       "      <td>2021-01-05 18:01:15</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>I have a thing for younger guys</td>\n",
       "      <td>First off Iâ€™d like to state that im sorry for ...</td>\n",
       "      <td>2022-08-21 04:35:03</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>479</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>I feel like I have lost in the game of life. H...</td>\n",
       "      <td>No matter what I do I am not finding happiness...</td>\n",
       "      <td>2022-05-10 22:04:39</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>130</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "131450                  Looking for hope (feeling fed up)   \n",
       "691395  Get motivated with determination you can do an...   \n",
       "275676                                     memory flashes   \n",
       "392360  I'll never get to live in the fantasy land for...   \n",
       "538129                       tips for managing the AAAA ?   \n",
       "402501                     I really canâ€™t get out of this   \n",
       "566855           anxiety over such insignificant thingsâ€¦.   \n",
       "357103               My dog died and I have nothing left.   \n",
       "443776                           Spiraling out of control   \n",
       "87944                   Pms exacerbating neediness for fp   \n",
       "496598                                              EMDR?   \n",
       "115086                        Is anyone on amitriptyline?   \n",
       "671805  is this my rejection sensitivity or am i allow...   \n",
       "412371                              My friends donâ€™t care   \n",
       "613187                Getting anxious about coming to gym   \n",
       "379648                             1st time on medication   \n",
       "140144            A mom learning a lot about BPD and DBT.   \n",
       "66199               Just received my diagnosis. Now what?   \n",
       "27126                     I have a thing for younger guys   \n",
       "341384  I feel like I have lost in the game of life. H...   \n",
       "\n",
       "                                                 selftext         created_utc  \\\n",
       "131450  My diagnosis is fairly new and I havent starte... 2020-05-30 22:47:57   \n",
       "691395     Like I just managed to cut with a safety razor 2020-05-17 15:31:50   \n",
       "275676  so, I used to have a really good memory\\n\\n&am... 2022-10-13 18:02:41   \n",
       "392360  I won't ever get to turn my fantasies into rea... 2022-03-01 07:58:19   \n",
       "538129  I've been medically diagnosed with a general a... 2021-08-06 01:54:21   \n",
       "402501  The last month my depression reach its lowest ... 2022-07-05 22:33:20   \n",
       "566855  just had to reschedule a doctorâ€™s appointment ... 2021-08-18 22:51:22   \n",
       "357103  My marriage isn't doing great. Dog was healthy... 2022-08-25 20:40:17   \n",
       "443776  Do you ever get to where you feel fine one min... 2022-05-09 02:03:26   \n",
       "87944   I've been working hard with my therapist on co... 2021-01-18 00:09:14   \n",
       "496598  Has anyone here used emdr therapy before? And ... 2022-02-27 04:59:27   \n",
       "115086  Whatâ€™s your experience with amitriptyline? Iâ€™m... 2020-06-30 08:41:15   \n",
       "671805  hi there! \\nso about two days ago i had what s... 2021-01-25 13:54:05   \n",
       "412371  Iâ€™ve been best friends with my group for over ... 2022-10-23 20:53:35   \n",
       "613187  I used to train by myself. Now I'm coming to n... 2021-07-20 11:43:14   \n",
       "379648  Holy crap, I have been chronically depressed f... 2022-03-15 18:59:20   \n",
       "140144  My 17yr old daughter is now beginning her jour... 2020-07-22 04:36:36   \n",
       "66199   My doctor just gave me a Bpd diagnosis. He is ... 2021-01-05 18:01:15   \n",
       "27126   First off Iâ€™d like to state that im sorry for ... 2022-08-21 04:35:03   \n",
       "341384  No matter what I do I am not finding happiness... 2022-05-10 22:04:39   \n",
       "\n",
       "        over_18 subreddit  title_total  title_chars  text_total  text_chars  \n",
       "131450    False    others            6           28         344        1414  \n",
       "691395    False    others            8           45          10          37  \n",
       "275676    False    others            2           13          91         424  \n",
       "392360    False    others           10           41          72         288  \n",
       "538129    False   Anxiety            6           23         113         506  \n",
       "402501    False    others            7           24         168         698  \n",
       "566855    False   Anxiety            5           36         192         860  \n",
       "357103    False    others            8           29         196         757  \n",
       "443776     True    others            4           21         146         650  \n",
       "87944     False    others            5           29          90         381  \n",
       "496598    False   Anxiety            1            5          14          61  \n",
       "115086    False    others            4           24          88         435  \n",
       "671805    False    others           16           63         239        1036  \n",
       "412371    False    others            4           18         438        1806  \n",
       "613187    False   Anxiety            6           30          49         221  \n",
       "379648    False    others            4           19         269        1148  \n",
       "140144    False    others            9           31          93         413  \n",
       "66199     False    others            6           32         104         420  \n",
       "27126     False    others            7           25         479        1874  \n",
       "341384    False    others           19           58         130         501  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f2631",
   "metadata": {
    "id": "308f2631"
   },
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74b01bc8",
   "metadata": {
    "id": "74b01bc8",
    "outputId": "469c851a-1cac-4601-9842-f191606a98c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Don\n",
      "[nltk_data]     Bosco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Don\n",
      "[nltk_data]     Bosco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Don\n",
      "[nltk_data]     Bosco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Don\n",
      "[nltk_data]     Bosco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "string.punctuation\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602e0791",
   "metadata": {
    "id": "602e0791",
    "outputId": "7f7c6d44-7af2-451e-daa5-90360e3e39fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_total</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131450</th>\n",
       "      <td>Looking for hope (feeling fed up)</td>\n",
       "      <td>My diagnosis is fairly new and I havent starte...</td>\n",
       "      <td>2020-05-30 22:47:57</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>344</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691395</th>\n",
       "      <td>Get motivated with determination you can do an...</td>\n",
       "      <td>Like I just managed to cut with a safety razor</td>\n",
       "      <td>2020-05-17 15:31:50</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275676</th>\n",
       "      <td>memory flashes</td>\n",
       "      <td>so, I used to have a really good memory\\n\\n&amp;am...</td>\n",
       "      <td>2022-10-13 18:02:41</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392360</th>\n",
       "      <td>I'll never get to live in the fantasy land for...</td>\n",
       "      <td>I won't ever get to turn my fantasies into rea...</td>\n",
       "      <td>2022-03-01 07:58:19</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ?</td>\n",
       "      <td>I've been medically diagnosed with a general a...</td>\n",
       "      <td>2021-08-06 01:54:21</td>\n",
       "      <td>False</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "131450                  Looking for hope (feeling fed up)   \n",
       "691395  Get motivated with determination you can do an...   \n",
       "275676                                     memory flashes   \n",
       "392360  I'll never get to live in the fantasy land for...   \n",
       "538129                       tips for managing the AAAA ?   \n",
       "\n",
       "                                                 selftext         created_utc  \\\n",
       "131450  My diagnosis is fairly new and I havent starte... 2020-05-30 22:47:57   \n",
       "691395     Like I just managed to cut with a safety razor 2020-05-17 15:31:50   \n",
       "275676  so, I used to have a really good memory\\n\\n&am... 2022-10-13 18:02:41   \n",
       "392360  I won't ever get to turn my fantasies into rea... 2022-03-01 07:58:19   \n",
       "538129  I've been medically diagnosed with a general a... 2021-08-06 01:54:21   \n",
       "\n",
       "        over_18 subreddit  title_total  title_chars  text_total  text_chars  \n",
       "131450    False    others            6           28         344        1414  \n",
       "691395    False    others            8           45          10          37  \n",
       "275676    False    others            2           13          91         424  \n",
       "392360    False    others           10           41          72         288  \n",
       "538129    False   Anxiety            6           23         113         506  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a94830d",
   "metadata": {
    "id": "0a94830d",
    "outputId": "40185dca-8439-4498-eb32-611bcc95657c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ? I've been medical...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦. just ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR? Has anyone here used emdr therapy before...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym I used to ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633253</th>\n",
       "      <td>Nicotine Helps me think I found without nicoti...</td>\n",
       "      <td>schizophrenia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 all_text      subreddit\n",
       "538129  tips for managing the AAAA ? I've been medical...        Anxiety\n",
       "566855  anxiety over such insignificant thingsâ€¦. just ...        Anxiety\n",
       "496598  EMDR? Has anyone here used emdr therapy before...        Anxiety\n",
       "613187  Getting anxious about coming to gym I used to ...        Anxiety\n",
       "633253  Nicotine Helps me think I found without nicoti...  schizophrenia"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['all_text'] = sampled_df['title'] + \" \" + sampled_df['selftext']\n",
    "\n",
    "df = sampled_df[['all_text', 'subreddit']]\n",
    "df = df[df['subreddit'] != 'others']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b468939",
   "metadata": {
    "id": "2b468939"
   },
   "outputs": [],
   "source": [
    "# Define the abbreviations dictionary\n",
    "abbr_dict = {\n",
    "    \"'cause\": \"because\",\n",
    "    \"ain't\": \"am not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"dont\": \"do not\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadnt\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hasnt\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"havent\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"i ve\": \"i have\",\n",
    "    \"imma\": \"i am going to\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"not've\": \"not have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"there're\": \"there are\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"wasnt\": \"was not\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"werent\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when're\": \"when are\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where're\": \"where are\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# Define the function to replace the abbreviations\n",
    "def replace_abbreviations(text):\n",
    "    # Replace 'â€™' with '\\'\n",
    "    text = re.sub('â€™', '\\'', text)\n",
    "\n",
    "    # Remove any word that starts with 'm' or 'f' followed by digits\n",
    "    text = re.sub(r'\\b[mf](\\d+)\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove any digit that is followed by 'm' or 'f'\n",
    "    text = re.sub(r'\\b(\\d+)[mf]\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace abbreviations with their full form\n",
    "    for word in text.split():\n",
    "        if word.lower() in abbr_dict:\n",
    "            text = re.sub(r'\\b{}\\b'.format(word), abbr_dict[word.lower()], text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Define the function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    emoji = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U00002500-\\U00002BEF\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoji, '', text)\n",
    "\n",
    "def remove_html(data):\n",
    "    html_tag=re.compile(r'<.*?>')\n",
    "    data=html_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "def remove_whitespaces(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']',' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7709a964",
   "metadata": {
    "id": "7709a964",
    "outputId": "65db3469-16d6-4c6f-a8fa-2541db6f218b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ? I've been medical...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[tips, managing, aaaa, medically, diagnosed, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦. just ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, insignificant, things, reschedule, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR? Has anyone here used emdr therapy before...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[emdr, anyone, used, emdr, therapy, effective]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym I used to ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[getting, anxious, coming, gym, used, train, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633253</th>\n",
       "      <td>Nicotine Helps me think I found without nicoti...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[nicotine, helps, think, found, without, nicot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 all_text      subreddit  \\\n",
       "538129  tips for managing the AAAA ? I've been medical...        Anxiety   \n",
       "566855  anxiety over such insignificant thingsâ€¦. just ...        Anxiety   \n",
       "496598  EMDR? Has anyone here used emdr therapy before...        Anxiety   \n",
       "613187  Getting anxious about coming to gym I used to ...        Anxiety   \n",
       "633253  Nicotine Helps me think I found without nicoti...  schizophrenia   \n",
       "\n",
       "                                                   tokens  \n",
       "538129  [tips, managing, aaaa, medically, diagnosed, g...  \n",
       "566855  [anxiety, insignificant, things, reschedule, d...  \n",
       "496598     [emdr, anyone, used, emdr, therapy, effective]  \n",
       "613187  [getting, anxious, coming, gym, used, train, c...  \n",
       "633253  [nicotine, helps, think, found, without, nicot...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning and tokenization\n",
    "def tokenization(text):\n",
    "    set_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    text = replace_abbreviations(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_whitespaces(text)\n",
    "    text = remove_digits(text)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    return [w for w in tokens if w not in set_stop_words]\n",
    "\n",
    "df['tokens']= df['all_text'].apply(lambda x: tokenization(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a74b93",
   "metadata": {
    "id": "91a74b93",
    "outputId": "6b2b989c-885a-4a24-c5fb-095923422c29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ? I've been medical...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[tips, managing, aaaa, medically, diagnosed, g...</td>\n",
       "      <td>[tip, manage, aaaa, medically, diagnose, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦. just ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, insignificant, things, reschedule, d...</td>\n",
       "      <td>[anxiety, insignificant, thing, reschedule, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR? Has anyone here used emdr therapy before...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[emdr, anyone, used, emdr, therapy, effective]</td>\n",
       "      <td>[emdr, anyone, use, emdr, therapy, effective]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym I used to ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[getting, anxious, coming, gym, used, train, c...</td>\n",
       "      <td>[get, anxious, come, gym, use, train, come, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633253</th>\n",
       "      <td>Nicotine Helps me think I found without nicoti...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[nicotine, helps, think, found, without, nicot...</td>\n",
       "      <td>[nicotine, help, think, find, without, nicotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525248</th>\n",
       "      <td>Weird feeling the past couple weeks Hello, Iâ€™m...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[weird, feeling, past, couple, weeks, hello, f...</td>\n",
       "      <td>[weird, feel, past, couple, week, hello, f, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612722</th>\n",
       "      <td>Does anyone else spiral when listening to anxi...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anyone, else, spiral, listening, anxiety, sto...</td>\n",
       "      <td>[anyone, else, spiral, listen, anxiety, story,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526416</th>\n",
       "      <td>ðŸ˜”ðŸ˜”ðŸ˜” Hi anxious nowâ€¦ about possible broken glas...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[hi, anxious, possible, broken, glass, eye, th...</td>\n",
       "      <td>[hi, anxious, possible, break, glass, eye, tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519916</th>\n",
       "      <td>MRI tomorrow and I'm really nervous My neurolo...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[mri, tomorrow, really, nervous, neurologist, ...</td>\n",
       "      <td>[mri, tomorrow, really, nervous, neurologist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491615</th>\n",
       "      <td>How can I deal with anxiety during exams? I ha...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[deal, anxiety, exams, diagnosed, generalized,...</td>\n",
       "      <td>[deal, anxiety, exam, diagnose, generalize, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475423</th>\n",
       "      <td>I debated in front of a large audience.. I had...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[debated, front, large, audience, first, debat...</td>\n",
       "      <td>[debate, front, large, audience, first, debate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557930</th>\n",
       "      <td>Any tips &amp;amp; strategies on how to manage bra...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[tips, amp, strategies, manage, brain, fog, he...</td>\n",
       "      <td>[tip, amp, strategy, manage, brain, fog, hello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537061</th>\n",
       "      <td>Why Is My Anxiety So Weird? (First Post Here) ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, weird, first, post, got, diagnosed, ...</td>\n",
       "      <td>[anxiety, weird, first, post, get, diagnose, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631654</th>\n",
       "      <td>Is it possible Is it possible that i have insi...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[possible, possible, insight, hallucinations, ...</td>\n",
       "      <td>[possible, possible, insight, hallucination, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558565</th>\n",
       "      <td>Is this anxiety? Multiple hours ago I was so e...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, multiple, hours, ago, extremely, diz...</td>\n",
       "      <td>[anxiety, multiple, hour, ago, extremely, dizz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475305</th>\n",
       "      <td>Panic Attack when i receive text from ex? I ge...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[panic, attack, receive, text, ex, get, panic,...</td>\n",
       "      <td>[panic, attack, receive, text, ex, get, panic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574395</th>\n",
       "      <td>Scared of telling my House Mate I want to get ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[scared, telling, house, mate, want, get, plac...</td>\n",
       "      <td>[scar, tell, house, mate, want, get, place, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574217</th>\n",
       "      <td>I Love My Sport But It Gives Me Anxiety I love...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[love, sport, gives, anxiety, love, sport, pla...</td>\n",
       "      <td>[love, sport, give, anxiety, love, sport, play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576061</th>\n",
       "      <td>Is my mom okay Do people always have signs of ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[mom, okay, people, always, signs, ms, worried...</td>\n",
       "      <td>[mom, okay, people, always, sign, m, worry, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638241</th>\n",
       "      <td>I saw a Psychiatrist for the first time yester...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[saw, psychiatrist, first, time, yesterday, fi...</td>\n",
       "      <td>[saw, psychiatrist, first, time, yesterday, fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 all_text      subreddit  \\\n",
       "538129  tips for managing the AAAA ? I've been medical...        Anxiety   \n",
       "566855  anxiety over such insignificant thingsâ€¦. just ...        Anxiety   \n",
       "496598  EMDR? Has anyone here used emdr therapy before...        Anxiety   \n",
       "613187  Getting anxious about coming to gym I used to ...        Anxiety   \n",
       "633253  Nicotine Helps me think I found without nicoti...  schizophrenia   \n",
       "525248  Weird feeling the past couple weeks Hello, Iâ€™m...        Anxiety   \n",
       "612722  Does anyone else spiral when listening to anxi...        Anxiety   \n",
       "526416  ðŸ˜”ðŸ˜”ðŸ˜” Hi anxious nowâ€¦ about possible broken glas...        Anxiety   \n",
       "519916  MRI tomorrow and I'm really nervous My neurolo...        Anxiety   \n",
       "491615  How can I deal with anxiety during exams? I ha...        Anxiety   \n",
       "475423  I debated in front of a large audience.. I had...        Anxiety   \n",
       "557930  Any tips &amp; strategies on how to manage bra...        Anxiety   \n",
       "537061  Why Is My Anxiety So Weird? (First Post Here) ...        Anxiety   \n",
       "631654  Is it possible Is it possible that i have insi...  schizophrenia   \n",
       "558565  Is this anxiety? Multiple hours ago I was so e...        Anxiety   \n",
       "475305  Panic Attack when i receive text from ex? I ge...        Anxiety   \n",
       "574395  Scared of telling my House Mate I want to get ...        Anxiety   \n",
       "574217  I Love My Sport But It Gives Me Anxiety I love...        Anxiety   \n",
       "576061  Is my mom okay Do people always have signs of ...        Anxiety   \n",
       "638241  I saw a Psychiatrist for the first time yester...  schizophrenia   \n",
       "\n",
       "                                                   tokens  \\\n",
       "538129  [tips, managing, aaaa, medically, diagnosed, g...   \n",
       "566855  [anxiety, insignificant, things, reschedule, d...   \n",
       "496598     [emdr, anyone, used, emdr, therapy, effective]   \n",
       "613187  [getting, anxious, coming, gym, used, train, c...   \n",
       "633253  [nicotine, helps, think, found, without, nicot...   \n",
       "525248  [weird, feeling, past, couple, weeks, hello, f...   \n",
       "612722  [anyone, else, spiral, listening, anxiety, sto...   \n",
       "526416  [hi, anxious, possible, broken, glass, eye, th...   \n",
       "519916  [mri, tomorrow, really, nervous, neurologist, ...   \n",
       "491615  [deal, anxiety, exams, diagnosed, generalized,...   \n",
       "475423  [debated, front, large, audience, first, debat...   \n",
       "557930  [tips, amp, strategies, manage, brain, fog, he...   \n",
       "537061  [anxiety, weird, first, post, got, diagnosed, ...   \n",
       "631654  [possible, possible, insight, hallucinations, ...   \n",
       "558565  [anxiety, multiple, hours, ago, extremely, diz...   \n",
       "475305  [panic, attack, receive, text, ex, get, panic,...   \n",
       "574395  [scared, telling, house, mate, want, get, plac...   \n",
       "574217  [love, sport, gives, anxiety, love, sport, pla...   \n",
       "576061  [mom, okay, people, always, signs, ms, worried...   \n",
       "638241  [saw, psychiatrist, first, time, yesterday, fi...   \n",
       "\n",
       "                                        lemmatized_tokens  \n",
       "538129  [tip, manage, aaaa, medically, diagnose, gener...  \n",
       "566855  [anxiety, insignificant, thing, reschedule, do...  \n",
       "496598      [emdr, anyone, use, emdr, therapy, effective]  \n",
       "613187  [get, anxious, come, gym, use, train, come, ne...  \n",
       "633253  [nicotine, help, think, find, without, nicotin...  \n",
       "525248  [weird, feel, past, couple, week, hello, f, ho...  \n",
       "612722  [anyone, else, spiral, listen, anxiety, story,...  \n",
       "526416  [hi, anxious, possible, break, glass, eye, tho...  \n",
       "519916  [mri, tomorrow, really, nervous, neurologist, ...  \n",
       "491615  [deal, anxiety, exam, diagnose, generalize, an...  \n",
       "475423  [debate, front, large, audience, first, debate...  \n",
       "557930  [tip, amp, strategy, manage, brain, fog, hello...  \n",
       "537061  [anxiety, weird, first, post, get, diagnose, g...  \n",
       "631654  [possible, possible, insight, hallucination, w...  \n",
       "558565  [anxiety, multiple, hour, ago, extremely, dizz...  \n",
       "475305  [panic, attack, receive, text, ex, get, panic,...  \n",
       "574395  [scar, tell, house, mate, want, get, place, ye...  \n",
       "574217  [love, sport, give, anxiety, love, sport, play...  \n",
       "576061  [mom, okay, people, always, sign, m, worry, mo...  \n",
       "638241  [saw, psychiatrist, first, time, yesterday, fi...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "word_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemm_text = [word_lemmatizer.lemmatize(word, pos=\"v\") for word in text]\n",
    "    lemm_text = [word_lemmatizer.lemmatize(word, pos=\"n\") for word in lemm_text]\n",
    "    lemm_text = [word_lemmatizer.lemmatize(word, pos=\"a\") for word in lemm_text]\n",
    "    lemm_text = [word_lemmatizer.lemmatize(word, pos=\"r\") for word in lemm_text]\n",
    "    lemm_text = [word_lemmatizer.lemmatize(word, pos=\"s\") for word in lemm_text]\n",
    "    return lemm_text\n",
    "\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lambda x:lemmatization(x))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ab1d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>padded_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538129</th>\n",
       "      <td>tips for managing the AAAA ? I've been medical...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[tips, managing, aaaa, medically, diagnosed, g...</td>\n",
       "      <td>[tip, manage, aaaa, medically, diagnose, gener...</td>\n",
       "      <td>[173, 233, 1749, 1750, 220, 234, 2, 167, 1751,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566855</th>\n",
       "      <td>anxiety over such insignificant thingsâ€¦. just ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, insignificant, things, reschedule, d...</td>\n",
       "      <td>[anxiety, insignificant, thing, reschedule, do...</td>\n",
       "      <td>[2, 1758, 13, 602, 128, 209, 222, 1759, 696, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496598</th>\n",
       "      <td>EMDR? Has anyone here used emdr therapy before...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[emdr, anyone, used, emdr, therapy, effective]</td>\n",
       "      <td>[emdr, anyone, use, emdr, therapy, effective]</td>\n",
       "      <td>[1277, 22, 73, 1277, 84, 826, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613187</th>\n",
       "      <td>Getting anxious about coming to gym I used to ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[getting, anxious, coming, gym, used, train, c...</td>\n",
       "      <td>[get, anxious, come, gym, use, train, come, ne...</td>\n",
       "      <td>[3, 34, 40, 1002, 73, 603, 40, 116, 1002, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633253</th>\n",
       "      <td>Nicotine Helps me think I found without nicoti...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[nicotine, helps, think, found, without, nicot...</td>\n",
       "      <td>[nicotine, help, think, find, without, nicotin...</td>\n",
       "      <td>[827, 15, 6, 54, 117, 827, 109, 168, 1004, 18,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525248</th>\n",
       "      <td>Weird feeling the past couple weeks Hello, Iâ€™m...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[weird, feeling, past, couple, weeks, hello, f...</td>\n",
       "      <td>[weird, feel, past, couple, week, hello, f, ho...</td>\n",
       "      <td>[111, 1, 105, 235, 59, 293, 1279, 418, 73, 89,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612722</th>\n",
       "      <td>Does anyone else spiral when listening to anxi...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anyone, else, spiral, listening, anxiety, sto...</td>\n",
       "      <td>[anyone, else, spiral, listen, anxiety, story,...</td>\n",
       "      <td>[22, 52, 385, 311, 2, 194, 16, 1771, 421, 89, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526416</th>\n",
       "      <td>ðŸ˜”ðŸ˜”ðŸ˜” Hi anxious nowâ€¦ about possible broken glas...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[hi, anxious, possible, broken, glass, eye, th...</td>\n",
       "      <td>[hi, anxious, possible, break, glass, eye, tho...</td>\n",
       "      <td>[239, 34, 357, 188, 1015, 276, 839, 358, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519916</th>\n",
       "      <td>MRI tomorrow and I'm really nervous My neurolo...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[mri, tomorrow, really, nervous, neurologist, ...</td>\n",
       "      <td>[mri, tomorrow, really, nervous, neurologist, ...</td>\n",
       "      <td>[840, 315, 12, 261, 841, 9, 840, 222, 116, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491615</th>\n",
       "      <td>How can I deal with anxiety during exams? I ha...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[deal, anxiety, exams, diagnosed, generalized,...</td>\n",
       "      <td>[deal, anxiety, exam, diagnose, generalize, an...</td>\n",
       "      <td>[92, 2, 472, 220, 1291, 2, 167, 27, 177, 1292,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475423</th>\n",
       "      <td>I debated in front of a large audience.. I had...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[debated, front, large, audience, first, debat...</td>\n",
       "      <td>[debate, front, large, audience, first, debate...</td>\n",
       "      <td>[1293, 713, 610, 1294, 43, 1293, 426, 610, 714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557930</th>\n",
       "      <td>Any tips &amp;amp; strategies on how to manage bra...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[tips, amp, strategies, manage, brain, fog, he...</td>\n",
       "      <td>[tip, amp, strategy, manage, brain, fog, hello...</td>\n",
       "      <td>[173, 121, 846, 233, 129, 530, 293, 1023, 1792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537061</th>\n",
       "      <td>Why Is My Anxiety So Weird? (First Post Here) ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, weird, first, post, got, diagnosed, ...</td>\n",
       "      <td>[anxiety, weird, first, post, get, diagnose, g...</td>\n",
       "      <td>[2, 111, 43, 131, 3, 220, 475, 1028, 111, 4, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631654</th>\n",
       "      <td>Is it possible Is it possible that i have insi...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[possible, possible, insight, hallucinations, ...</td>\n",
       "      <td>[possible, possible, insight, hallucination, w...</td>\n",
       "      <td>[357, 357, 617, 537, 117, 617, 12, 617, 618, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558565</th>\n",
       "      <td>Is this anxiety? Multiple hours ago I was so e...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[anxiety, multiple, hours, ago, extremely, diz...</td>\n",
       "      <td>[anxiety, multiple, hour, ago, extremely, dizz...</td>\n",
       "      <td>[2, 477, 103, 85, 241, 1008, 96, 4, 1805, 1033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475305</th>\n",
       "      <td>Panic Attack when i receive text from ex? I ge...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[panic, attack, receive, text, ex, get, panic,...</td>\n",
       "      <td>[panic, attack, receive, text, ex, get, panic,...</td>\n",
       "      <td>[39, 35, 481, 400, 391, 3, 39, 35, 481, 400, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574395</th>\n",
       "      <td>Scared of telling my House Mate I want to get ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[scared, telling, house, mate, want, get, plac...</td>\n",
       "      <td>[scar, tell, house, mate, want, get, place, ye...</td>\n",
       "      <td>[46, 69, 118, 1034, 9, 3, 126, 27, 177, 425, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574217</th>\n",
       "      <td>I Love My Sport But It Gives Me Anxiety I love...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[love, sport, gives, anxiety, love, sport, pla...</td>\n",
       "      <td>[love, sport, give, anxiety, love, sport, play...</td>\n",
       "      <td>[196, 437, 72, 2, 196, 437, 338, 53, 1316, 53,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576061</th>\n",
       "      <td>Is my mom okay Do people always have signs of ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>[mom, okay, people, always, signs, ms, worried...</td>\n",
       "      <td>[mom, okay, people, always, sign, m, worry, mo...</td>\n",
       "      <td>[236, 438, 21, 44, 546, 1053, 41, 236, 91, 840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638241</th>\n",
       "      <td>I saw a Psychiatrist for the first time yester...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>[saw, psychiatrist, first, time, yesterday, fi...</td>\n",
       "      <td>[saw, psychiatrist, first, time, yesterday, fi...</td>\n",
       "      <td>[407, 487, 43, 8, 426, 203, 440, 426, 242, 101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 all_text      subreddit  \\\n",
       "538129  tips for managing the AAAA ? I've been medical...        Anxiety   \n",
       "566855  anxiety over such insignificant thingsâ€¦. just ...        Anxiety   \n",
       "496598  EMDR? Has anyone here used emdr therapy before...        Anxiety   \n",
       "613187  Getting anxious about coming to gym I used to ...        Anxiety   \n",
       "633253  Nicotine Helps me think I found without nicoti...  schizophrenia   \n",
       "525248  Weird feeling the past couple weeks Hello, Iâ€™m...        Anxiety   \n",
       "612722  Does anyone else spiral when listening to anxi...        Anxiety   \n",
       "526416  ðŸ˜”ðŸ˜”ðŸ˜” Hi anxious nowâ€¦ about possible broken glas...        Anxiety   \n",
       "519916  MRI tomorrow and I'm really nervous My neurolo...        Anxiety   \n",
       "491615  How can I deal with anxiety during exams? I ha...        Anxiety   \n",
       "475423  I debated in front of a large audience.. I had...        Anxiety   \n",
       "557930  Any tips &amp; strategies on how to manage bra...        Anxiety   \n",
       "537061  Why Is My Anxiety So Weird? (First Post Here) ...        Anxiety   \n",
       "631654  Is it possible Is it possible that i have insi...  schizophrenia   \n",
       "558565  Is this anxiety? Multiple hours ago I was so e...        Anxiety   \n",
       "475305  Panic Attack when i receive text from ex? I ge...        Anxiety   \n",
       "574395  Scared of telling my House Mate I want to get ...        Anxiety   \n",
       "574217  I Love My Sport But It Gives Me Anxiety I love...        Anxiety   \n",
       "576061  Is my mom okay Do people always have signs of ...        Anxiety   \n",
       "638241  I saw a Psychiatrist for the first time yester...  schizophrenia   \n",
       "\n",
       "                                                   tokens  \\\n",
       "538129  [tips, managing, aaaa, medically, diagnosed, g...   \n",
       "566855  [anxiety, insignificant, things, reschedule, d...   \n",
       "496598     [emdr, anyone, used, emdr, therapy, effective]   \n",
       "613187  [getting, anxious, coming, gym, used, train, c...   \n",
       "633253  [nicotine, helps, think, found, without, nicot...   \n",
       "525248  [weird, feeling, past, couple, weeks, hello, f...   \n",
       "612722  [anyone, else, spiral, listening, anxiety, sto...   \n",
       "526416  [hi, anxious, possible, broken, glass, eye, th...   \n",
       "519916  [mri, tomorrow, really, nervous, neurologist, ...   \n",
       "491615  [deal, anxiety, exams, diagnosed, generalized,...   \n",
       "475423  [debated, front, large, audience, first, debat...   \n",
       "557930  [tips, amp, strategies, manage, brain, fog, he...   \n",
       "537061  [anxiety, weird, first, post, got, diagnosed, ...   \n",
       "631654  [possible, possible, insight, hallucinations, ...   \n",
       "558565  [anxiety, multiple, hours, ago, extremely, diz...   \n",
       "475305  [panic, attack, receive, text, ex, get, panic,...   \n",
       "574395  [scared, telling, house, mate, want, get, plac...   \n",
       "574217  [love, sport, gives, anxiety, love, sport, pla...   \n",
       "576061  [mom, okay, people, always, signs, ms, worried...   \n",
       "638241  [saw, psychiatrist, first, time, yesterday, fi...   \n",
       "\n",
       "                                        lemmatized_tokens  \\\n",
       "538129  [tip, manage, aaaa, medically, diagnose, gener...   \n",
       "566855  [anxiety, insignificant, thing, reschedule, do...   \n",
       "496598      [emdr, anyone, use, emdr, therapy, effective]   \n",
       "613187  [get, anxious, come, gym, use, train, come, ne...   \n",
       "633253  [nicotine, help, think, find, without, nicotin...   \n",
       "525248  [weird, feel, past, couple, week, hello, f, ho...   \n",
       "612722  [anyone, else, spiral, listen, anxiety, story,...   \n",
       "526416  [hi, anxious, possible, break, glass, eye, tho...   \n",
       "519916  [mri, tomorrow, really, nervous, neurologist, ...   \n",
       "491615  [deal, anxiety, exam, diagnose, generalize, an...   \n",
       "475423  [debate, front, large, audience, first, debate...   \n",
       "557930  [tip, amp, strategy, manage, brain, fog, hello...   \n",
       "537061  [anxiety, weird, first, post, get, diagnose, g...   \n",
       "631654  [possible, possible, insight, hallucination, w...   \n",
       "558565  [anxiety, multiple, hour, ago, extremely, dizz...   \n",
       "475305  [panic, attack, receive, text, ex, get, panic,...   \n",
       "574395  [scar, tell, house, mate, want, get, place, ye...   \n",
       "574217  [love, sport, give, anxiety, love, sport, play...   \n",
       "576061  [mom, okay, people, always, sign, m, worry, mo...   \n",
       "638241  [saw, psychiatrist, first, time, yesterday, fi...   \n",
       "\n",
       "                                          padded_encoding  \n",
       "538129  [173, 233, 1749, 1750, 220, 234, 2, 167, 1751,...  \n",
       "566855  [2, 1758, 13, 602, 128, 209, 222, 1759, 696, 4...  \n",
       "496598  [1277, 22, 73, 1277, 84, 826, 0, 0, 0, 0, 0, 0...  \n",
       "613187  [3, 34, 40, 1002, 73, 603, 40, 116, 1002, 14, ...  \n",
       "633253  [827, 15, 6, 54, 117, 827, 109, 168, 1004, 18,...  \n",
       "525248  [111, 1, 105, 235, 59, 293, 1279, 418, 73, 89,...  \n",
       "612722  [22, 52, 385, 311, 2, 194, 16, 1771, 421, 89, ...  \n",
       "526416  [239, 34, 357, 188, 1015, 276, 839, 358, 14, 1...  \n",
       "519916  [840, 315, 12, 261, 841, 9, 840, 222, 116, 13,...  \n",
       "491615  [92, 2, 472, 220, 1291, 2, 167, 27, 177, 1292,...  \n",
       "475423  [1293, 713, 610, 1294, 43, 1293, 426, 610, 714...  \n",
       "557930  [173, 121, 846, 233, 129, 530, 293, 1023, 1792...  \n",
       "537061  [2, 111, 43, 131, 3, 220, 475, 1028, 111, 4, 2...  \n",
       "631654  [357, 357, 617, 537, 117, 617, 12, 617, 618, 3...  \n",
       "558565  [2, 477, 103, 85, 241, 1008, 96, 4, 1805, 1033...  \n",
       "475305  [39, 35, 481, 400, 391, 3, 39, 35, 481, 400, 3...  \n",
       "574395  [46, 69, 118, 1034, 9, 3, 126, 27, 177, 425, 2...  \n",
       "574217  [196, 437, 72, 2, 196, 437, 338, 53, 1316, 53,...  \n",
       "576061  [236, 438, 21, 44, 546, 1053, 41, 236, 91, 840...  \n",
       "638241  [407, 487, 43, 8, 426, 203, 440, 426, 242, 101...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "# Counting the unique number of tokens for num_words in text_encoding\n",
    "\n",
    "lemmatized_words = [word for word_list in df['lemmatized_tokens'] for word in word_list]\n",
    "unique_words = len(set(lemmatized_words))\n",
    "\n",
    "# Encoding and padding\n",
    "\n",
    "def text_encoding(lemmatized_texts, num_words):\n",
    "    vocabulary = defaultdict(int)\n",
    "    fdist = nltk.FreqDist()\n",
    "\n",
    "    all_lemmatized_words = [word for word_list in lemmatized_texts for word in word_list]\n",
    "    \n",
    "    for word in all_lemmatized_words:\n",
    "        fdist[word] += 1\n",
    "\n",
    "    common_words = fdist.most_common(num_words)\n",
    "\n",
    "    for idx, word in enumerate(common_words):\n",
    "        vocabulary[word[0]] = (idx + 1)\n",
    "\n",
    "    encoded_texts = []\n",
    "    texts4encoding = []\n",
    "\n",
    "    for tokens in lemmatized_texts:\n",
    "        temp_codes = []\n",
    "        temp_words = []\n",
    "\n",
    "        for word in tokens:\n",
    "            if word in vocabulary.keys():\n",
    "                temp_codes.append(vocabulary[word])\n",
    "                temp_words.append(word)\n",
    "\n",
    "        encoded_texts.append(temp_codes)\n",
    "        texts4encoding.append(temp_words)\n",
    "\n",
    "    vector_size = max(len(x) for x in encoded_texts)\n",
    "\n",
    "    return encoded_texts, texts4encoding, vector_size\n",
    "\n",
    "def codes_padding(X_encoded_texts):\n",
    "    pad_value = 0\n",
    "    padded_codes = []\n",
    "\n",
    "    codes_from_texts = copy.deepcopy(X_encoded_texts)\n",
    "    \n",
    "    # vector_size in text_encoding\n",
    "    max_length = max(len(encoded_text) for encoded_text in codes_from_texts)\n",
    "\n",
    "    for encoded_text in codes_from_texts:\n",
    "        while len(encoded_text) < max_length:\n",
    "            encoded_text.append(pad_value)\n",
    "        padded_codes.append(encoded_text)\n",
    "\n",
    "    return padded_codes\n",
    "\n",
    "df['padded_encoding'] = codes_padding(text_encoding(df['lemmatized_tokens'], unique_words)[0])\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fbdbc",
   "metadata": {},
   "source": [
    "### Model 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04a25853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9309207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetMapping(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class   DatasetLoading:\n",
    "    \n",
    "    def __init__(self, padded_codes, targets):\n",
    "        \n",
    "        self.X = padded_codes\n",
    "        self.y = targets\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        \n",
    "    def data_split(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.20, random_state=20231116)    \n",
    "\n",
    "    def data_mapping(self):\n",
    "        \n",
    "        self.train = DatasetMapping(self.X_train, self.y_train)\n",
    "        self.test = DatasetMapping(self.X_test, self.y_test)\n",
    "\n",
    "    def data_loading(self):\n",
    "        self.loader_train = DataLoader(self.train, batch_size=params.batch_size)\n",
    "        self.loader_test = DataLoader(self.test, batch_size=params.batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97f58f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Parameters:\n",
    "    # Preprocessing parameters\n",
    "    vector_size: int = len(df['padded_encoding'].iloc[0])\n",
    "    num_words: int = unique_words\n",
    "    test_size = 0.20         \n",
    "    random_state = 42\n",
    "   \n",
    "    # Model parameters\n",
    "    embedding_dim: int = 256\n",
    "    num_layers: int = 2 # number of lstm layers\n",
    "    num_classes: int = df['subreddit'].nunique()\n",
    "    #out_size: int = 32\n",
    "    #tride: int = 2\n",
    "    #dilation: int = 2\n",
    "       \n",
    "    # Training parameters\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 0.001\n",
    "    dropout: float = 0.5\n",
    "    \n",
    "params=Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4059aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.tensor(df['padded_encoding'].tolist())\n",
    "y_data = torch.tensor(df['subreddit'].astype('category').cat.codes.tolist(), dtype=torch.long)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataset = TensorDataset(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4db90654",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl = DatasetLoading(X_data, y_data)\n",
    "dsl.data_split()\n",
    "dsl.data_mapping()\n",
    "dsl.data_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db295449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.ModuleList):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        \n",
    "        self.batch_size = params.batch_size\n",
    "        self.hidden_dim = params.embedding_dim\n",
    "        self.num_layers = params.num_layers\n",
    "        self.input_size = params.num_words+1\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.hidden_dim, out_features=256)\n",
    "        self.fc2 = nn.Linear(256, params.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h = torch.zeros((self.num_layers, x.size(0), self.hidden_dim))\n",
    "        c = torch.zeros((self.num_layers, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        torch.nn.init.xavier_normal_(h)\n",
    "        torch.nn.init.xavier_normal_(c)\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm(out, (h,c))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu_(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946c093",
   "metadata": {},
   "source": [
    "### Training and Testing @ 10 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbe373c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.39493, Training Accuracy: 0.5067\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 2, loss: 0.22821, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 3, loss: 0.21454, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 4, loss: 0.16193, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 5, loss: 0.15040, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 6, loss: 0.16640, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 7, loss: 0.15050, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 8, loss: 0.15260, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 9, loss: 0.13233, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 10, loss: 0.16451, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_classes = df['subreddit'].nunique()\n",
    "\n",
    "lstm_model = LSTMNet(params)\n",
    "optimizer = optim.RMSprop(lstm_model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "loader_train = dsl.loader_train\n",
    "loader_test = dsl.loader_test\n",
    "y_train = dsl.y_train\n",
    "y_test = dsl.y_test\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Training phase\n",
    "for epoch in range(params.epochs):\n",
    "    \n",
    "    # Set model in training mode\n",
    "    lstm_model.train()\n",
    "    train_predictions = []\n",
    "    \n",
    "    for x_batch, y_batch in loader_train:\n",
    "        y_batch = y_batch.view(-1).type(torch.LongTensor)  # Convert to 1D LongTensor        \n",
    "        # Print target labels for debugging\n",
    "\n",
    "        # Feed the model\n",
    "        y_pred = lstm_model(x_batch)\n",
    "\n",
    "        # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "        y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_batch)\n",
    "        \n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Gradients calculation\n",
    "        loss.backward()\n",
    "         \n",
    "        # Gradients update\n",
    "        optimizer.step()\n",
    "\n",
    "        train_predictions.append(y_pred)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_predictions = torch.cat(train_predictions, dim=0)\n",
    "    train_accuracy = calculate_accuracy(train_predictions, y_train)\n",
    "\n",
    "    print(\"Epoch: %d, loss: %.5f, Training Accuracy: %.4f\" % (epoch+1, loss.item(), train_accuracy))\n",
    "    \n",
    "    # Validation phase\n",
    "    lstm_model.eval()\n",
    "    test_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader_test:\n",
    "            y_batch = y_batch.view(-1).type(torch.LongTensor)\n",
    "\n",
    "            # Feed the model\n",
    "            y_pred = lstm_model(x_batch)\n",
    "\n",
    "            # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "            y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "            test_predictions.append(y_pred)\n",
    "\n",
    "        # Calculate testing accuracy\n",
    "        test_predictions = torch.cat(test_predictions, dim=0)\n",
    "        test_accuracy = calculate_accuracy(test_predictions, y_test)\n",
    "\n",
    "        print(\"Validation Accuracy: %.4f\" % test_accuracy)\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1c9a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Parameters:\n",
    "    # Preprocessing parameters\n",
    "    vector_size: int = len(df['padded_encoding'].iloc[0])\n",
    "    num_words: int = unique_words\n",
    "    test_size = 0.20         \n",
    "    random_state = 42\n",
    "   \n",
    "    # Model parameters\n",
    "    embedding_dim: int = 256\n",
    "    num_layers: int = 2 # number of lstm layers\n",
    "    num_classes: int = df['subreddit'].nunique()\n",
    "    #out_size: int = 32\n",
    "    #tride: int = 2\n",
    "    #dilation: int = 2\n",
    "       \n",
    "    # Training parameters\n",
    "    epochs: int = 50\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 0.001\n",
    "    dropout: float = 0.5\n",
    "    \n",
    "params=Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6680e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.34524, Training Accuracy: 0.4667\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 2, loss: 0.22010, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 3, loss: 0.19532, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 4, loss: 0.15538, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 5, loss: 0.15747, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 6, loss: 0.14592, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 7, loss: 0.14985, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 8, loss: 0.14941, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 9, loss: 0.14599, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 10, loss: 0.15858, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 11, loss: 0.14493, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 12, loss: 0.13485, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 13, loss: 0.14507, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 14, loss: 0.16304, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 15, loss: 0.15111, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 16, loss: 0.14086, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 17, loss: 0.16080, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 18, loss: 0.16532, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 19, loss: 0.16347, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 20, loss: 0.15241, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 21, loss: 0.15037, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 22, loss: 0.13639, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 23, loss: 0.16088, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 24, loss: 0.15748, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 25, loss: 0.15926, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 26, loss: 0.13513, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 27, loss: 0.14922, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 28, loss: 0.15885, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 29, loss: 0.14318, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 30, loss: 0.14893, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 31, loss: 0.15185, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 32, loss: 0.14916, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 33, loss: 0.15673, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 34, loss: 0.16733, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 35, loss: 0.14488, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 36, loss: 0.14672, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 37, loss: 0.13564, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 38, loss: 0.14748, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 39, loss: 0.14997, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 40, loss: 0.13830, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 41, loss: 0.13610, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 42, loss: 0.17813, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 43, loss: 0.15542, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 44, loss: 0.14789, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 45, loss: 0.14587, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 46, loss: 0.13021, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 47, loss: 0.14574, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 48, loss: 0.14072, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 49, loss: 0.14393, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 50, loss: 0.15128, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_classes = df['subreddit'].nunique()\n",
    "\n",
    "lstm_model = LSTMNet(params)\n",
    "optimizer = optim.RMSprop(lstm_model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "loader_train = dsl.loader_train\n",
    "loader_test = dsl.loader_test\n",
    "y_train = dsl.y_train\n",
    "y_test = dsl.y_test\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Training phase\n",
    "for epoch in range(params.epochs):\n",
    "    \n",
    "    # Set model in training mode\n",
    "    lstm_model.train()\n",
    "    train_predictions = []\n",
    "    \n",
    "    for x_batch, y_batch in loader_train:\n",
    "        y_batch = y_batch.view(-1).type(torch.LongTensor)  # Convert to 1D LongTensor        \n",
    "        # Print target labels for debugging\n",
    "\n",
    "        # Feed the model\n",
    "        y_pred = lstm_model(x_batch)\n",
    "\n",
    "        # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "        y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_batch)\n",
    "        \n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Gradients calculation\n",
    "        loss.backward()\n",
    "         \n",
    "        # Gradients update\n",
    "        optimizer.step()\n",
    "\n",
    "        train_predictions.append(y_pred)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_predictions = torch.cat(train_predictions, dim=0)\n",
    "    train_accuracy = calculate_accuracy(train_predictions, y_train)\n",
    "\n",
    "    print(\"Epoch: %d, loss: %.5f, Training Accuracy: %.4f\" % (epoch+1, loss.item(), train_accuracy))\n",
    "    \n",
    "    # Validation phase\n",
    "    lstm_model.eval()\n",
    "    test_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader_test:\n",
    "            y_batch = y_batch.view(-1).type(torch.LongTensor)\n",
    "\n",
    "            # Feed the model\n",
    "            y_pred = lstm_model(x_batch)\n",
    "\n",
    "            # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "            y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "            test_predictions.append(y_pred)\n",
    "\n",
    "        # Calculate testing accuracy\n",
    "        test_predictions = torch.cat(test_predictions, dim=0)\n",
    "        test_accuracy = calculate_accuracy(test_predictions, y_test)\n",
    "\n",
    "        print(\"Validation Accuracy: %.4f\" % test_accuracy)\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36325d2",
   "metadata": {},
   "source": [
    "### Training and Testing @ 100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "000a7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Parameters:\n",
    "    # Preprocessing parameters\n",
    "    vector_size: int = len(df['padded_encoding'].iloc[0])\n",
    "    num_words: int = unique_words\n",
    "    test_size = 0.20         \n",
    "    random_state = 42\n",
    "   \n",
    "    # Model parameters\n",
    "    embedding_dim: int = 256\n",
    "    num_layers: int = 2 # number of lstm layers\n",
    "    num_classes: int = df['subreddit'].nunique()\n",
    "    #out_size: int = 32\n",
    "    #tride: int = 2\n",
    "    #dilation: int = 2\n",
    "       \n",
    "    # Training parameters\n",
    "    epochs: int = 100\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 0.001\n",
    "    dropout: float = 0.5\n",
    "    \n",
    "params=Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24c2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.24102, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 2, loss: 0.28415, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 3, loss: 0.20961, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 4, loss: 0.14672, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 5, loss: 0.16217, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 6, loss: 0.14990, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 7, loss: 0.15753, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 8, loss: 0.14421, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 9, loss: 0.14663, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 10, loss: 0.15575, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 11, loss: 0.14184, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 12, loss: 0.13687, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 13, loss: 0.15517, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 14, loss: 0.15434, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 15, loss: 0.14573, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 16, loss: 0.16311, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 17, loss: 0.15525, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 18, loss: 0.14774, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 19, loss: 0.13087, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 20, loss: 0.15762, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 21, loss: 0.14539, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 22, loss: 0.14024, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 23, loss: 0.13907, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 24, loss: 0.14305, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 25, loss: 0.14615, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 26, loss: 0.14230, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 27, loss: 0.14942, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 28, loss: 0.15542, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 29, loss: 0.16309, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 30, loss: 0.15153, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 31, loss: 0.13058, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 32, loss: 0.14763, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 33, loss: 0.15638, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 34, loss: 0.15172, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 35, loss: 0.15888, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 36, loss: 0.15117, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 37, loss: 0.15627, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 38, loss: 0.14990, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 39, loss: 0.13568, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 40, loss: 0.14129, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 41, loss: 0.14486, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 42, loss: 0.15269, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 43, loss: 0.14990, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 44, loss: 0.14568, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 45, loss: 0.13562, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 46, loss: 0.15502, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 47, loss: 0.15836, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 48, loss: 0.14436, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 49, loss: 0.14474, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 50, loss: 0.14116, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 51, loss: 0.15622, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 52, loss: 0.14386, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 53, loss: 0.14152, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 54, loss: 0.16030, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 55, loss: 0.16123, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 56, loss: 0.15067, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 57, loss: 0.15882, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 58, loss: 0.15074, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 59, loss: 0.16086, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 60, loss: 0.16437, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 61, loss: 0.14586, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 62, loss: 0.14229, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 63, loss: 0.13601, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 64, loss: 0.16130, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 65, loss: 0.14796, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 66, loss: 0.15049, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 67, loss: 0.13009, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 68, loss: 0.14574, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 69, loss: 0.14980, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 70, loss: 0.15741, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 71, loss: 0.14273, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 72, loss: 0.15217, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 73, loss: 0.14013, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 74, loss: 0.15851, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 75, loss: 0.15159, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 76, loss: 0.14456, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 77, loss: 0.13808, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 78, loss: 0.15247, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 79, loss: 0.14254, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 80, loss: 0.15208, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 81, loss: 0.15377, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 82, loss: 0.14859, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 83, loss: 0.15903, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 84, loss: 0.15205, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 85, loss: 0.14025, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 86, loss: 0.15170, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 87, loss: 0.16237, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 88, loss: 0.15160, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 89, loss: 0.13818, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 90, loss: 0.14748, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 91, loss: 0.15579, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 92, loss: 0.15279, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 93, loss: 0.15324, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 94, loss: 0.15667, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 95, loss: 0.14666, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 96, loss: 0.15116, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 97, loss: 0.13963, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 98, loss: 0.15609, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 99, loss: 0.14436, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Epoch: 100, loss: 0.14866, Training Accuracy: 0.9511\n",
      "Validation Accuracy: 0.8772\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_classes = df['subreddit'].nunique()\n",
    "\n",
    "lstm_model = LSTMNet(params)\n",
    "optimizer = optim.RMSprop(lstm_model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "loader_train = dsl.loader_train\n",
    "loader_test = dsl.loader_test\n",
    "y_train = dsl.y_train\n",
    "y_test = dsl.y_test\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Training phase\n",
    "for epoch in range(params.epochs):\n",
    "    \n",
    "    # Set model in training mode\n",
    "    lstm_model.train()\n",
    "    train_predictions = []\n",
    "    \n",
    "    for x_batch, y_batch in loader_train:\n",
    "        y_batch = y_batch.view(-1).type(torch.LongTensor)  # Convert to 1D LongTensor        \n",
    "        # Print target labels for debugging\n",
    "\n",
    "        # Feed the model\n",
    "        y_pred = lstm_model(x_batch)\n",
    "\n",
    "        # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "        y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_batch)\n",
    "        \n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Gradients calculation\n",
    "        loss.backward()\n",
    "         \n",
    "        # Gradients update\n",
    "        optimizer.step()\n",
    "\n",
    "        train_predictions.append(y_pred)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_predictions = torch.cat(train_predictions, dim=0)\n",
    "    train_accuracy = calculate_accuracy(train_predictions, y_train)\n",
    "\n",
    "    print(\"Epoch: %d, loss: %.5f, Training Accuracy: %.4f\" % (epoch+1, loss.item(), train_accuracy))\n",
    "    \n",
    "    # Validation phase\n",
    "    lstm_model.eval()\n",
    "    test_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader_test:\n",
    "            y_batch = y_batch.view(-1).type(torch.LongTensor)\n",
    "\n",
    "            # Feed the model\n",
    "            y_pred = lstm_model(x_batch)\n",
    "\n",
    "            # Reshape y_pred to have the shape (batch_size, num_classes)\n",
    "            y_pred = y_pred.view(-1, num_classes)\n",
    "\n",
    "            test_predictions.append(y_pred)\n",
    "\n",
    "        # Calculate testing accuracy\n",
    "        test_predictions = torch.cat(test_predictions, dim=0)\n",
    "        test_accuracy = calculate_accuracy(test_predictions, y_test)\n",
    "\n",
    "        print(\"Validation Accuracy: %.4f\" % test_accuracy)\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be3636",
   "metadata": {},
   "source": [
    "### LSTM Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24fcade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import Precision\n",
    "from torchmetrics import Recall\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83742de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87719\n",
      "Precision: 0.76947\n",
      "Recall: 0.87719\n",
      "F1 Score: 0.81981\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "lstm_model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "# Start evaluation phase\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in loader_test:\n",
    "        y_pred = lstm_model(x_batch)\n",
    "        test_predictions += torch.argmax(y_pred, dim=-1).cpu().numpy().tolist()\n",
    "\n",
    "# Flatten the true labels and predicted labels\n",
    "y_test_flat = y_test.view(-1).cpu().numpy().tolist()\n",
    "test_predictions_flat = test_predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_flat, test_predictions_flat)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_flat, test_predictions_flat, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Test Accuracy: {:.5f}\".format(accuracy))\n",
    "print(\"Precision: {:.5f}\".format(precision))\n",
    "print(\"Recall: {:.5f}\".format(recall))\n",
    "print(\"F1 Score: {:.5f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
